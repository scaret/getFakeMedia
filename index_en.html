<html xmlns="http://www.w3.org/1999/html">
    <head>
        <meta charset="utf-8">
        <link rel="icon" href="data:,">
    </head>
    <body>
    <h1>fakeMediaDevices.getFakeMedia</h1>
    <i style="color:darkblue">
In Real Time Communication(RTC) development, we often need to obtain a MediaStream from the camera<br>
for encoding and transmission purposes. The fakeMediaDevices library simulates a camera stream to<br>
ensure a stable input during testing. Additionally, it offers various parameters to support<br/>
testing with different focuses.<br/>
<br/>
This page is a visual rendering showcase. In actual use, developers can access the WebRTC object
programmatically for transmission.<br/>
</i>
<br/>
<a href="https://github.com/scaret/getFakeMedia" target="_blank">Github</a> by Lu Yuchun
<br/><br/>

    <h2>1. Default Options</h2>
    <i style="color:darkblue">
Most areas of the video remain static to avoid encoding resource usage,<br>
while audio and video remain smooth for stability monitoring.
    </i>

    <pre>
        const fakeMedia = fakeMediaDevices.getFakeMedia({
            audio: true,
            video: true,
        })
        const fakeMediaStream = new MediaStream([fakeMedia.audio.track, fakeMedia.video.track])
        document.getElementById("video-default").srcObject = fakeMediaStream
    </pre>
    <button id="play-btn-default">Play</button>
    <video id="video-default" controls autoplay playsinline></video>
    <script>
        document.getElementById("play-btn-default").onclick = async ()=>{
            const fakeMedia = fakeMediaDevices.getFakeMedia({
                audio: true,
                video: true,
            })
            const fakeMediaStream = new MediaStream([fakeMedia.audio.track, fakeMedia.video.track])
            document.getElementById("video-default").srcObject = fakeMediaStream
        }
    </script>


    <h2>2. Stereo Audio + Configurable Video (Resolution, Frame Rate) with Noise in Right Channel</h2>
    <i style="color:darkblue">
Audio: Verifies stereo encoding, decoding, and playback support in the audio pipeline and devices.<br/>
Video: Verifies device and codec support for resolution and frame rate.
    </i>
    <pre>
        const fakeMedia = fakeMediaDevices.getFakeMedia({
            audio: {
                channelCount: 2,
                left: {
                    data: "bbdbbjyy",
                    loop: true,
                    gain: 1,
                },
                right: {
                    data: "mmdmmjwp",
                    loop: true,
                    gain: 0.5,
                    noise: {
                        gain: 0.05,
                    },
                },
            },
            video: {
                width: 1024,
                height: 768,
                frameRate: 15,
            },
        })
        const fakeMediaStream = new MediaStream([fakeMedia.audio.track, fakeMedia.video.track])
        document.getElementById("video-stereo").srcObject = fakeMediaStream
    </pre>
    <button id="play-btn-stereo">Play</button>
    <video id="video-stereo" controls autoplay playsinline></video>
    <script>
        document.getElementById("play-btn-stereo").onclick = async ()=>{
            const fakeMedia = fakeMediaDevices.getFakeMedia({
                audio: {
                    channelCount: 2,
                    left: {
                        data: "bbdbbjyy",
                        loop: true,
                        gain: 1,
                    },
                    right: {
                        data: "mmdmmjwp",
                        loop: true,
                        gain: 0.5,
                        noise: {
                            gain: 0.05,
                        },
                    },
                },
                video: {
                    width: 1024,
                    height: 768,
                    frameRate: 15,
                },
            })
            const fakeMediaStream = new MediaStream([fakeMedia.audio.track, fakeMedia.video.track])
            document.getElementById("video-stereo").srcObject = fakeMediaStream
        }
    </script>


    <h2>3. Background Replacement</h2>
<i style="color:darkblue">
Verifies the Wasm pipeline for video pre-processing
</i>

    <pre>
        const bgImg = new Image()
        bgImg.src = "./assets/img/mountain.jpeg"
        document.getElementById("play-btn-background").onclick = async ()=>{
            const fakeMedia = fakeMediaDevices.getFakeMedia({
                audio: true,
                video: {
                    type: "background",
                    bgImg,
                },
            })
            const fakeMediaStream = new MediaStream([fakeMedia.audio.track, fakeMedia.video.track])
            document.getElementById("video-background").srcObject = fakeMediaStream
        }
    </pre>
    <button id="play-btn-background">Play</button>
    <video id="video-background" controls autoplay playsinline></video>
    <script>
        const bgImg = new Image()
        bgImg.src = "./assets/img/mountain.jpeg"
        document.getElementById("play-btn-background").onclick = async ()=>{
            const fakeMedia = fakeMediaDevices.getFakeMedia({
                audio: true,
                video: {
                    type: "background",
                    bgImg,
                },
            })
            const fakeMediaStream = new MediaStream([fakeMedia.audio.track, fakeMedia.video.track])
            document.getElementById("video-background").srcObject = fakeMediaStream
        }
    </script>



    <h2>4. Random Pixels</h2>
    <i style="color:darkblue">
This demo creates a high-information-density camera environment to stress test the entire<br/>
communication process. Notably, when WebRTC performance is limited, it allows trade-offs<br/>
between resolution and image quality, making it ideal for such scenarios.<br/>
    </i>
    <pre>
        document.getElementById("play-btn-random").onclick = async ()=>{
            const fakeMedia = fakeMediaDevices.getFakeMedia({
                audio: false,
                video: {
                    type: "randomcolor",
                    bgImg,
                },
            })
            const fakeMediaStream = new MediaStream([fakeMedia.video.track])
            document.getElementById("video-randomcolor").srcObject = fakeMediaStream
        }
    </pre>
    <button id="play-btn-randomcolor">Play</button>
    <video id="video-randomcolor" controls autoplay playsinline></video>
    <script>
        document.getElementById("play-btn-randomcolor").onclick = async ()=>{
            const fakeMedia = fakeMediaDevices.getFakeMedia({
                audio: false,
                video: {
                    type: "randomcolor",
                    bgImg,
                },
            })
            const fakeMediaStream = new MediaStream([fakeMedia.video.track])
            document.getElementById("video-randomcolor").srcObject = fakeMediaStream
        }
    </script>

    <h2>5. Default Video Stream + Phase-Canceling Stereo Sine Waves</h2>
<i style="color:darkblue">
Some devices do not support stereo playback and merge all channels during playback.<br/>
If the energy of both channels cancels out at the same time, the audio disappears.<br/>
This demo demonstrates this phenomenon. Notably, if the entire pipeline fails to synchronize<br/>
the left and right channels precisely, the otherwise silent audio may produce sound.<br/>
</i>
    <pre>
        const fakeMedia = fakeMediaDevices.getFakeMedia({
            audio: {
                type: "oscstereo",
            },
            video: true,
        })
        const fakeMediaStream = new MediaStream([fakeMedia.audio.track, fakeMedia.video.track])
        document.getElementById("video-oscstereo").srcObject = fakeMediaStream
    </pre>
    <button id="play-btn-oscstereo">Play</button>
    <button id="mute-left-oscstereo">Close Left Channel</button>
    <button id="unmute-left-oscstereo">Open Left Channel</button>
    <button id="mute-right-oscstereo">Close Right Channel</button>
    <button id="unmute-right-oscstereo">Open Right Channel</button>
    <br/>
    <video id="video-oscstereo" controls autoplay playsinline></video>
    <script>
        let fakeMedia = null
        document.getElementById("play-btn-oscstereo").onclick = async ()=>{
            fakeMedia = fakeMediaDevices.getFakeMedia({
                audio: {
                    type: "oscstereo",
                },
                video: true,
            })
            const fakeMediaStream = new MediaStream([fakeMedia.audio.track, fakeMedia.video.track])
            document.getElementById("video-oscstereo").srcObject = fakeMediaStream
        }
        document.getElementById("mute-left-oscstereo").onclick = async ()=>{
            fakeMedia.audio.gainNodeLeft.gain.value = 0
            console.log("left", fakeMedia.audio.gainNodeLeft.gain.value, "right", fakeMedia.audio.gainNodeRight.gain.value)
        }
        document.getElementById("unmute-left-oscstereo").onclick = async ()=>{
            fakeMedia.audio.gainNodeLeft.gain.value = 1
            console.log("left", fakeMedia.audio.gainNodeLeft.gain.value, "right", fakeMedia.audio.gainNodeRight.gain.value)
        }
        document.getElementById("mute-right-oscstereo").onclick = async ()=>{
            fakeMedia.audio.gainNodeRight.gain.value = 0
            console.log("left", fakeMedia.audio.gainNodeLeft.gain.value, "right", fakeMedia.audio.gainNodeRight.gain.value)
        }
        document.getElementById("unmute-right-oscstereo").onclick = async ()=>{
            fakeMedia.audio.gainNodeRight.gain.value = 1
            console.log("left", fakeMedia.audio.gainNodeLeft.gain.value, "right", fakeMedia.audio.gainNodeRight.gain.value)
        }
    </script>

    <script src="./assets/axios/dist/axios.min.js"></script>
    <script src="./assets/qrcode/qrcode.js"></script>
    <script src="./dist/fakeMediaDevices.js"></script>
    </body>

    <script>
        // new QRCode(document.getElementById("qrcode"), "http://jindo.dev.naver.com/collie");
    </script>
</html>
